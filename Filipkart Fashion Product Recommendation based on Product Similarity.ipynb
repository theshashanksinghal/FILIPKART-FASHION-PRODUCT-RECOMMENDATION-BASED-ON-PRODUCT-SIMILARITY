{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "###### NOTE: this model can be improved by using different CNN models for calculating image dense vector representation and the prediction can be increase by cropping the images close to the human( i.e. with less white background).\n",
    "\n",
    "## Assumptions:\n",
    "1.No seller will publish their item in wrong category.\n",
    "\n",
    "2.In a Reccomender system Products with same titles but different size will be displayed as one product under which sizes will be product variant. So I'll consider them as duplicate and add them as duplicate items.\n",
    "\n",
    "3.All product titles start by brand name.\n",
    "\n",
    "4.I am considering the products which are identical in appearence(can have different sizes) and product variants in different colour as identical. \n",
    "\n",
    "## Definition of duplicate:\n",
    "Reference: https://www.netstrategy.it/en/seo-blog/duplicated-content-ecommerce\n",
    "\n",
    "What is duplicated content?\n",
    "\n",
    "According to the Mountain View official sources, duplicated content is defined as a significant portion of text that is similar, or almost identical to, another who resides in the same website or an external website.\n",
    "\n",
    "Let look at Google’s original definition:\n",
    "\n",
    " “[…] Duplicate content generally refers to substantive blocks of content within or across domains that either completely match other content or are appreciably similar. Mostly, this is not deceptive in origin […]. If your site contains multiple pages with largely identical content, there are a number of ways you can indicate your preferred URL to Google. In the rare cases in which Google perceives that duplicate content may be shown with intent to manipulate our rankings and deceive our users, we’ll also make appropriate adjustments in the indexing and ranking of the sites involved.” (Fonte:https://support.google.com/webmasters/answer/66359?hl=en )\n",
    "\n",
    "As you can imagine, not all duplicated contents found on the web are malicious. Regardless, Google adopted the necessary measures to indicate which text parts would be duplicated and which would be the version to point in order to avoid unpleasant inconveniences and guarantee correct indexing of the website.\n",
    "\n",
    "\n",
    "Reference: https://www.netstrategy.it/en/seo-blog/duplicated-content-ecommerce\n",
    "\n",
    "#### Types of duplicate content\n",
    "\n",
    "    Copied content – Is where one web site copies information from another. With e-commerce web sites this is very common. Product descriptions are copied from the manufacture’s web site and cause duplicate content over multiple properties (sometimes thousands of them).\n",
    "    Multiple URLs – The use of search filters within e-commerce sites creates numerous possibilities for visitors to find a single product. Each unique search query will create a new URL, but the content looks similar or exactly the same. Other related duplicate pages could result from URL setup and server side settings.\n",
    "    Similar product – Arises when a site uses one product description to sell other versions of the same product. Other versions could be color, size, etc.\n",
    "    Closely related content – When one narrow topic is explained multiple times on multiple pages. This is very common on web sites with a blog and causes content cannibalization.\n",
    "### In this project I am considering Two different case:\n",
    "#### 1. Exactly same product with different sizes or colour.\n",
    "#### 2. SIMILAR PRODUCT as duplicates.\n",
    "\n",
    "###### I will calculate both of them separately and then combine them afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy for the efficient matrix calculation\n",
    "import numpy as np\n",
    "#pandas for loading data into dataframe and for performing operations on the dataframe\n",
    "import pandas as pd\n",
    "#tqdm to show the progress of the process\n",
    "from tqdm import tqdm_notebook\n",
    "#for Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#for tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#for calculating cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#for capturing a particular pattern in a  string\n",
    "import re\n",
    "#for joining two lists componentwise.\n",
    "import itertools\n",
    "#for downloading all the images\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "#for calculting cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (11,12,19,20,21,24,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#since some rows have more entries as no of column given. therefore i need to ignore those lines.\n",
    "data=pd.read_csv(\"small-2oq-c1r.csv\",usecols=['productId', 'title', 'description', 'imageUrlStr', 'mrp','sellingPrice', 'specialPrice', 'productUrl', 'categories','productBrand', 'productFamily', 'inStock', 'codAvailable','offers', 'discount', 'shippingCharges', 'deliveryTime', 'size','color', 'sizeUnit', 'storage', 'displaySize', 'keySpecsStr','detailedSpecsStr', 'specificationList', 'sellerName','sellerAverageRating', 'sellerNoOfRatings', 'sellerNoOfReviews','sleeve', 'neck', 'idealFor'])#error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['productId', 'title', 'description', 'imageUrlStr', 'mrp',\n",
       "       'sellingPrice', 'specialPrice', 'productUrl', 'categories',\n",
       "       'productBrand', 'productFamily', 'inStock', 'codAvailable',\n",
       "       'offers', 'discount', 'shippingCharges', 'deliveryTime', 'size',\n",
       "       'color', 'sizeUnit', 'storage', 'displaySize', 'keySpecsStr',\n",
       "       'detailedSpecsStr', 'specificationList', 'sellerName',\n",
       "       'sellerAverageRating', 'sellerNoOfRatings', 'sellerNoOfReviews',\n",
       "       'sleeve', 'neck', 'idealFor'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each product have 32 features in the raw dataset\n",
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll now select only those products which belongs to only \"top's category\n",
    "#selecting tops_data\n",
    "data=data[data[\"categories\"].str.contains(\">Tops\",na=False)]\n",
    "#reseting the indexing because tops_data indexing was same as the parent dataframe i.e. data\n",
    "data.reset_index(drop=True)\n",
    "#saving this dataset to new csv file \"tops_data.csv \n",
    "data.to_csv(\"tops_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (19,20,21,24,26,27,28,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions (347669, 32)\n"
     ]
    }
   ],
   "source": [
    "#loading the saved tops_data csv file into pandas dataframe\n",
    "data=pd.read_csv(\"tops_data.csv\")\n",
    "print(\"Data dimensions\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions (347669, 9)\n"
     ]
    }
   ],
   "source": [
    "#out of 33 features we'll be using only few features for our task.\n",
    "data=data[['productId', 'title', 'description', 'imageUrlStr','categories','productBrand','size','color','detailedSpecsStr']]\n",
    "print(\"Data dimensions\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count               347669\n",
      "unique              347579\n",
      "top       TOPEAZFCZQ28HVNR\n",
      "freq                     2\n",
      "Name: productId, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for productId\n",
    "print(data['productId'].describe())\n",
    "#By observing the frequency=2 it means that there is duplicate productids\n",
    "#There are no NaN values in productId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                            347664\n",
      "unique                                                            50050\n",
      "top       Snoogg Casual Sleeveless Graphic Print Women's Multicolor Top\n",
      "freq                                                               3525\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for titles\n",
    "print(data['title'].describe())\n",
    "#so there are many products with same product title\n",
    "#there are 5 products without title name \"NaN\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Snoogg Casual Sleeveless Graphic Print Women's Multicolor Top           3525\n",
       "Diaz Casual Short Sleeve Solid Women's Multicolor Top                   1428\n",
       "Uptown 18 Casual Short Sleeve Printed Women's White Top                 1176\n",
       "Uptown 18 Casual Short Sleeve Printed Women's Black Top                 1124\n",
       "Friskers Casual Sleeveless Solid Women's Multicolor Top                  725\n",
       "Uptown 18 Casual Short Sleeve Printed Women's Red Top                    617\n",
       "Amoya Casual Sleeveless Solid Women's Multicolor Top                     602\n",
       "Uptown 18 Casual Short Sleeve Printed Women's Green Top                  597\n",
       "Uptown 18 Casual Short Sleeve Printed Women's Blue Top                   596\n",
       "Uptown 18 Casual Short Sleeve Printed Women's Grey Top                   588\n",
       "Uptown 18 Casual Short Sleeve Printed Women's Yellow Top                 578\n",
       "Stop Look Casual 3/4th Sleeve Printed Women's Multicolor Top             493\n",
       "Piftif Beach Wear Sleeveless Solid Women's Multicolor Top                426\n",
       "Mustard Casual 3/4th Sleeve Printed Women's Multicolor Top               403\n",
       "Vero Moda Casual Sleeveless Solid Women's White Top                      366\n",
       "Uptown 18 Casual Sleeveless Printed Women's White Top                    365\n",
       "Uptown 18 Casual Sleeveless Printed Women's Black Top                    351\n",
       "The Gud Look Casual 3/4th Sleeve Printed Women's Multicolor Top          326\n",
       "Vero Moda Casual Short Sleeve Printed Women's White Top                  317\n",
       "Skyline Casual 3/4th Sleeve Printed Women's Multicolor Top               316\n",
       "Only Casual Sleeveless Solid Women's Blue Top                            308\n",
       "Only Casual Sleeveless Solid Women's Black Top                           300\n",
       "Campus Sutra Casual 3/4th Sleeve Solid Women's Multicolor Top            290\n",
       "Arovi Casual 3/4th Sleeve Floral Print Women's Multicolor Top            286\n",
       "Renka Casual Short Sleeve Solid Women's Pink Top                         284\n",
       "Vero Moda Casual Short Sleeve Solid Women's White Top                    284\n",
       "Only Casual Sleeveless Solid Women's White Top                           272\n",
       "Kalt Casual 3/4th Sleeve Self Design Women's Multicolor Top              271\n",
       "Only Casual Short Sleeve Printed Women's White Top                       255\n",
       "Piftif Casual Sleeveless Solid Women's Multicolor Top                    254\n",
       "                                                                        ... \n",
       "Fabomen Casual Sleeveless Printed Women's Green Top                        1\n",
       "ETRU Party Sleeveless Solid Women's Pink Top                               1\n",
       "PEP18 Casual Short Sleeve Printed Women's Green, Black Top                 1\n",
       "ZOEFEMME Casual Full Sleeve Solid Women's Grey Top                         1\n",
       "Vanya Enterprises Casual Full Sleeve Solid Women's Black Top               1\n",
       "Colors Couture Casual Short Sleeve Striped Women's White Top               1\n",
       "Mustard Casual 3/4th Sleeve Self Design Women's Beige Top                  1\n",
       "ShopMore Casual Cap Sleeve Printed Women's White Top                       1\n",
       "Inspire World Casual Short Sleeve Solid Women's Orange, White Top          1\n",
       "Y&I Formal Short Sleeve Solid Women's Black Top                            1\n",
       "Sams Collection Casual Full Sleeve Printed Women's White Top               1\n",
       "Oxolloxo Casual Short Sleeve Solid Women's Multicolor Top                  1\n",
       "Global Desi Casual Short Sleeve Printed Women's Brown, White Top           1\n",
       "Roadster Casual Cap Sleeve Solid Women's Beige Top                         1\n",
       "Rasada Party 3/4th Sleeve Solid Women's Black Top                          1\n",
       "FRENCHCREATIONS Casual Cap Sleeve Striped Women's Multicolor Top           1\n",
       "Damsel Casual Short Sleeve Floral Print Women's Black Top                  1\n",
       "SbuyS Casual 3/4th Sleeve Self Design Women's Pink Top                     1\n",
       "Debenhams Casual Sleeveless Solid Women's Black Top                        1\n",
       "9teenAGAIN Casual Short Sleeve Self Design Women's Pink Top                1\n",
       "Dovekie Formal Full Sleeve Floral Print Women's White, Green Top           1\n",
       "Globus Party Sleeveless Striped Women's Multicolor Top                     1\n",
       "fashion fakir Casual Sleeveless Printed Women's Black Top                  1\n",
       "GSI Casual Full Sleeve Printed Women's Yellow Top                          1\n",
       "Stylesambram Casual Short Sleeve Solid Women's Orange Top                  1\n",
       "Svt Ada Collections Casual Short Sleeve Floral Print Women's Red Top       1\n",
       "Prnas Casual Short Sleeve Floral Print Women's White Top                   1\n",
       "YES TEN Casual Sleeveless Solid Women's White Top                          1\n",
       "FNKY Casual 3/4th Sleeve Self Design Women's Pink Top                      1\n",
       "Riot Jeans Casual Short Sleeve Solid Women's White Top                     1\n",
       "Name: title, Length: 50050, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                                                                  215905\n",
      "unique                                                                                                  31941\n",
      "top       Round neck Crop top with cool and amazing prints which makes you feel comfortable for whole day....\n",
      "freq                                                                                                     5109\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for description\n",
    "print(data['description'].describe())\n",
    "#There are 347669-215905=131764 values which are \"NaN\".\n",
    "#So we'll not use description for our task.\n",
    "data=data[['productId', 'title', 'imageUrlStr','categories','productBrand','size','color','detailedSpecsStr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                                                                  347669\n",
      "unique                                                                                                  87969\n",
      "top       http://img.fkcdn.com/image/top/f/g/8/aarz009-aarzoo-m-original-imaej8seyxbdvuhg.jpeg;http://img....\n",
      "freq                                                                                                      150\n",
      "Name: imageUrlStr, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for imageUrlStr\n",
    "print(data['imageUrlStr'].describe())\n",
    "#all the values are present\n",
    "#there are some images which are same for many product. Max frequency is 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                     347669\n",
      "unique                                                         5\n",
      "top       Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops\n",
      "freq                                                      333187\n",
      "Name: categories, dtype: object\n",
      "Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops      333187\n",
      "Apparels>Women>Fusion Wear>Shirts, Tops & Tunics>Tops        12458\n",
      "Apparels>Women>Maternity Wear>Shirts, Tops & Tunics>Tops      1257\n",
      "Apparels>Kids>Girls>T-Shirts & Tops>Tops                       696\n",
      "Apparels>Kids>Infants>Baby Girls>T-Shirts & Tops>Tops           71\n",
      "Name: categories, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#basic stats for categories\n",
    "print(data['categories'].describe())\n",
    "print(data['categories'].value_counts())\n",
    "#all values are present\n",
    "#there are only 5 categories in category section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count        347667\n",
      "unique         2354\n",
      "top       Vero Moda\n",
      "freq           8770\n",
      "Name: productBrand, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for productBrand\n",
    "print(data['productBrand'].describe())\n",
    "# There are total 2354 product brands in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     347669\n",
      "unique        83\n",
      "top            M\n",
      "freq       73265\n",
      "Name: size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for size\n",
    "print(data['size'].describe())\n",
    "#all rows have data\n",
    "#there are only 83 different sizes in pur dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     347024\n",
      "unique      6912\n",
      "top        Black\n",
      "freq       42575\n",
      "Name: color, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for color\n",
    "print(data['color'].describe())\n",
    "#there are some fields which doesnt contain colour\n",
    "#there are 6912 unique colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                                           346640\n",
      "unique                                                                           24173\n",
      "top       Round Neck, Short Sleeve;Fabric: Cotton;Pattern: Printed;Type: Top;Pack of 1\n",
      "freq                                                                              7350\n",
      "Name: detailedSpecsStr, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#basic stats for detailedSpecsStr\n",
    "print(data['detailedSpecsStr'].describe())\n",
    "#There are some fileds in which Detailed specification is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions (346633, 8)\n"
     ]
    }
   ],
   "source": [
    "#removing those rows which don't have titles.\n",
    "data = data.loc[~data['title'].isnull()]\n",
    "#removing those rows which don't have product brand.\n",
    "data = data.loc[~data['productBrand'].isnull()]\n",
    "#removing those rows which don't have detailedSpecsStr.\n",
    "data = data.loc[~data['detailedSpecsStr'].isnull()]\n",
    "print(\"Dataset dimensions\",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll remove the duplicate product ids and save it in new csv file for continuing my task from here. we'll also slice the image url to get the perfect url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used for splitting the data.\n",
    "def splitting(imgUrl):\n",
    "    return imgUrl.split(\";\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll remove the duplicate product and keep only one copy of duplicate product.so we removed 90 rows from the dataset.\n",
    "data=data.drop_duplicates(subset=[\"productId\"], keep='first', inplace=False)\n",
    "data[\"imageUrlStr\"]=data[\"imageUrlStr\"].map(splitting)\n",
    "data.reset_index(drop=True)\n",
    "#saving this dataset to new csv file \"clean_tops_data.csv \"\n",
    "data.to_csv(\"clean_tops_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions (346543, 8)\n"
     ]
    }
   ],
   "source": [
    "#loading the saved clean_tops_data csv file into pandas dataframe\n",
    "data=pd.read_csv(\"clean_tops_data.csv\")\n",
    "print(\"Data dimensions\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removal of products with short title: 345994\n"
     ]
    }
   ],
   "source": [
    "# Remove All products with very few words in title\n",
    "data_sorted = data[data['title'].apply(lambda x: len(x.split())>4)]\n",
    "print(\"After removal of products with short title:\", data_sorted.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>title</th>\n",
       "      <th>imageUrlStr</th>\n",
       "      <th>categories</th>\n",
       "      <th>productBrand</th>\n",
       "      <th>size</th>\n",
       "      <th>color</th>\n",
       "      <th>detailedSpecsStr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232623</th>\n",
       "      <td>TOPER5RZG2JHTGFB</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XS</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329521</th>\n",
       "      <td>TOPER4ZERMKX9BGY</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XL</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232801</th>\n",
       "      <td>TOPER4ZEVAKBXRFH</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>L</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300795</th>\n",
       "      <td>TOPER4Z6AU328YRZ</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>S</td>\n",
       "      <td>mustred</td>\n",
       "      <td>U Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232281</th>\n",
       "      <td>TOPER4ZE8HNKPP92</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XXL</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               productId  \\\n",
       "232623  TOPER5RZG2JHTGFB   \n",
       "329521  TOPER4ZERMKX9BGY   \n",
       "232801  TOPER4ZEVAKBXRFH   \n",
       "300795  TOPER4Z6AU328YRZ   \n",
       "232281  TOPER4ZE8HNKPP92   \n",
       "\n",
       "                                                         title  \\\n",
       "232623  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "329521  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "232801  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "300795  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "232281  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "\n",
       "                                                                                      imageUrlStr  \\\n",
       "232623  http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "329521  http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "232801  http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "300795  http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "232281  http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "\n",
       "                                                    categories productBrand  \\\n",
       "232623  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   \n",
       "329521  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   \n",
       "232801  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   \n",
       "300795  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   \n",
       "232281  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   \n",
       "\n",
       "       size    color  \\\n",
       "232623   XS  mustard   \n",
       "329521   XL  mustard   \n",
       "232801    L  mustard   \n",
       "300795    S  mustred   \n",
       "232281  XXL  mustard   \n",
       "\n",
       "                                                                   detailedSpecsStr  \n",
       "232623     Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "329521  Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "232801     Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "300795         U Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "232281     Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the whole data based on title (alphabetical order of title)\n",
    "#This is done so that we will be able to notice that some products have exactly same title but differ in only size or color.\n",
    "#here inplace parameter is True to change the data frame itself.\n",
    "data_sorted.sort_values('title',inplace=True,ascending=False)\n",
    "data_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to diplay the whole title we'll increase the column width to 100 which is 50 as default.\n",
    "pd.options.display.max_colwidth=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all these statistics i came to the conclusion that i cant use \"only\" titles or detailed specification for the detection of duplicate item as there are many products with exactly same title and detailed specification but different images. SO we have to consider the images along with the titles and detailed specification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>title</th>\n",
       "      <th>imageUrlStr</th>\n",
       "      <th>categories</th>\n",
       "      <th>productBrand</th>\n",
       "      <th>size</th>\n",
       "      <th>color</th>\n",
       "      <th>detailedSpecsStr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOPER5RZG2JHTGFB</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XS</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPER4ZERMKX9BGY</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XL</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOPER4ZEVAKBXRFH</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>L</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOPER4Z6AU328YRZ</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>S</td>\n",
       "      <td>mustred</td>\n",
       "      <td>U Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPER4ZE8HNKPP92</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XXL</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOPER4ZEGCBGPZPX</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Yellow Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>M</td>\n",
       "      <td>mustard</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOPER4WDNVWSFFPH</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Red Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XS</td>\n",
       "      <td>red</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOPER4WHPM3ZKFM9</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Red Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>M</td>\n",
       "      <td>red</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOPER4PXZWAENZGX</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Red Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>L</td>\n",
       "      <td>red</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOPER6F9KZHFM82D</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Red Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XXL</td>\n",
       "      <td>red</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TOPER4WHD7QMWRM8</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Red Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XL</td>\n",
       "      <td>red</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOPER4WK3B8WW8ZB</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Red Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>S</td>\n",
       "      <td>red</td>\n",
       "      <td>Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TOPER7ZBE7ZVEHM5</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Pink Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/h/m/5/xs-t00144-zink-london-original-imaer4ej5kxhcqty.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>XS</td>\n",
       "      <td>pink</td>\n",
       "      <td>V-Neck, Sleeveless;Fabric: Cotton;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TOPER4ZEHYHHNHGS</td>\n",
       "      <td>zink london Casual Sleeveless Solid Women's Pink Top</td>\n",
       "      <td>http://img.fkcdn.com/image/top/m/m/e/xs-t00147-zink-london-original-imaer4f6hgpn3xzb.jpeg</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tunics&gt;Tops</td>\n",
       "      <td>zink london</td>\n",
       "      <td>S</td>\n",
       "      <td>peach</td>\n",
       "      <td>V-Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           productId                                                   title  \\\n",
       "0   TOPER5RZG2JHTGFB  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "1   TOPER4ZERMKX9BGY  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "2   TOPER4ZEVAKBXRFH  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "3   TOPER4Z6AU328YRZ  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "4   TOPER4ZE8HNKPP92  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "5   TOPER4ZEGCBGPZPX  zink london Casual Sleeveless Solid Women's Yellow Top   \n",
       "6   TOPER4WDNVWSFFPH     zink london Casual Sleeveless Solid Women's Red Top   \n",
       "7   TOPER4WHPM3ZKFM9     zink london Casual Sleeveless Solid Women's Red Top   \n",
       "8   TOPER4PXZWAENZGX     zink london Casual Sleeveless Solid Women's Red Top   \n",
       "9   TOPER6F9KZHFM82D     zink london Casual Sleeveless Solid Women's Red Top   \n",
       "10  TOPER4WHD7QMWRM8     zink london Casual Sleeveless Solid Women's Red Top   \n",
       "11  TOPER4WK3B8WW8ZB     zink london Casual Sleeveless Solid Women's Red Top   \n",
       "12  TOPER7ZBE7ZVEHM5    zink london Casual Sleeveless Solid Women's Pink Top   \n",
       "13  TOPER4ZEHYHHNHGS    zink london Casual Sleeveless Solid Women's Pink Top   \n",
       "\n",
       "                                                                                   imageUrlStr  \\\n",
       "0    http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "1    http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "2    http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "3    http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "4    http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "5    http://img.fkcdn.com/image/top/b/g/y/xs-t00146-zink-london-original-imaer4eummptmeyf.jpeg   \n",
       "6   http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg   \n",
       "7   http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg   \n",
       "8   http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg   \n",
       "9   http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg   \n",
       "10  http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg   \n",
       "11  http://img.fkcdn.com/image/top/r/m/8/xxl-t00161-zink-london-original-imaer4j6dpbws4yh.jpeg   \n",
       "12   http://img.fkcdn.com/image/top/h/m/5/xs-t00144-zink-london-original-imaer4ej5kxhcqty.jpeg   \n",
       "13   http://img.fkcdn.com/image/top/m/m/e/xs-t00147-zink-london-original-imaer4f6hgpn3xzb.jpeg   \n",
       "\n",
       "                                                categories productBrand size  \\\n",
       "0   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   XS   \n",
       "1   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   XL   \n",
       "2   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    L   \n",
       "3   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    S   \n",
       "4   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london  XXL   \n",
       "5   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    M   \n",
       "6   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   XS   \n",
       "7   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    M   \n",
       "8   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    L   \n",
       "9   Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london  XXL   \n",
       "10  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   XL   \n",
       "11  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    S   \n",
       "12  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london   XS   \n",
       "13  Apparels>Women>Western Wear>Shirts, Tops & Tunics>Tops  zink london    S   \n",
       "\n",
       "      color  \\\n",
       "0   mustard   \n",
       "1   mustard   \n",
       "2   mustard   \n",
       "3   mustred   \n",
       "4   mustard   \n",
       "5   mustard   \n",
       "6       red   \n",
       "7       red   \n",
       "8       red   \n",
       "9       red   \n",
       "10      red   \n",
       "11      red   \n",
       "12     pink   \n",
       "13    peach   \n",
       "\n",
       "                                                               detailedSpecsStr  \n",
       "0      Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "1   Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "2      Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "3          U Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "4      Round Neck, Sleeveless;Fabric: knitts;Pattern: Solid;Type: Top;Pack of 1  \n",
       "5   Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "6   Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "7   Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "8   Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "9   Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "10  Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "11  Round Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  \n",
       "12         V-Neck, Sleeveless;Fabric: Cotton;Pattern: Solid;Type: Top;Pack of 1  \n",
       "13      V-Neck, Sleeveless;Fabric: Georgette;Pattern: Solid;Type: Top;Pack of 1  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted.to_csv(\"sorted_tops_data.csv\",index=False)\n",
    "data_sorted1=pd.read_csv(\"sorted_tops_data.csv\")\n",
    "data_sorted1.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Converting image into vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for downloading images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sorted1.to_csv(\"final_sort.csv\",index=False)\n",
    "data_sorted1=pd.read_csv(\"final_sort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading images \n",
    "rm_ls=[]\n",
    "data_sorted_new=data_sorted2.copy()\n",
    "for index, row in data_sorted2.iterrows():\n",
    "        try:\n",
    "            url = row['imageUrlStr']\n",
    "            response = requests.get(url)\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            img.save('C:/Users/Hp/Desktop/infilect/tops/'+str(index)+'_'+row['productId']+'.jpeg')\n",
    "        except OSError :\n",
    "            rm_ls.append(index)\n",
    "            data_sorted_new=data_sorted_new[data_sorted_new.index!=index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for converting images to dense vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'topss/'\n",
    "nb_train_samples = 21096\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    \n",
    "    #Function to compute VGG-16 CNN for image feature extraction.\n",
    "    \n",
    "    asins = []\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    for i in generator.filenames:\n",
    "        asins.append(i[2:-5])\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    bottleneck_features_train = bottleneck_features_train.reshape((21096,-1))\n",
    "    \n",
    "    np.save(open('data_cnn_features_21k.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('data_cnn_feature_procuctid_g21k.npy', 'wb'), np.array(asins))\n",
    "    \n",
    "\n",
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select some rows which i have already calculated the vector representation for testing.\n",
    "in_name=np.load(\"data_cnn_feature_procuctid_g21k.npy\")\n",
    "cnn_features=np.load(\"data_cnn_features_21k.npy\")\n",
    "#in_name3k=np.load(\"data_cnn_in_names10k.npy\")\n",
    "#cnn_features3k=np.load(\"data_cnn_features10k.npy\")\n",
    "in_name1=[]\n",
    "for i in in_name:\n",
    "    inn=i.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "    in_name1.append(int(inn))\n",
    "in_name=np.array(in_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_name_lt=np.sort(in_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting only those rows for which i have converted their image into dense vector.\n",
    "data_sorted1=data_sorted1.loc[in_name_lt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21075, 9)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted1=data_sorted1.loc[~data_sorted1['detailedSpecsStr'].isnull()]\n",
    "data_sorted1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable which holds the index of the data as the indexes are not continuous.\n",
    "indices = []\n",
    "for i,row in data_sorted1.iterrows():\n",
    "    indices.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for calcultaing duplicate based on difference in only product attributes (like size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for checking similarity\n",
    "def check_similarity(l,m):\n",
    "    \n",
    "    sim=cosine_similarity(cnn_features[np.where(in_name==l)[0]].reshape(1,-1),cnn_features[np.where(in_name==m)[0]].reshape(1,-1))\n",
    "    if sim > 0.90:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "#products without any duplicate titles.\n",
    "dedup_prodid=[]\n",
    "#dictinary store the product as key and their duplictes as values.\n",
    "\n",
    "dup_dict={}\n",
    "\n",
    "r_i=0\n",
    "i=0\n",
    "j=0\n",
    "#list to track the record of the productid processed before.\n",
    "marker=[]\n",
    "start_i=0\n",
    "num_data=data_sorted1.shape[0]\n",
    "while i < num_data and j<num_data:\n",
    "    if start_i == 1:\n",
    "        i = j_skipped\n",
    "        start_i=0\n",
    "    previous_i=i\n",
    "    #store the words of title as list in a.\n",
    "    a=data_sorted1['title'].loc[indices[i]].split()\n",
    "\n",
    "    #now we will search for similar product one by one\n",
    "    j=i+1\n",
    "    #for storing the duplicate product ids.\n",
    "    dup_list=[]\n",
    "\n",
    "    while j < num_data:\n",
    "\n",
    "        #store the words of title as list in b.\n",
    "        b=data_sorted1['title'].loc[indices[j]].split()\n",
    "        #maximum length of the strings.\n",
    "        length=max(len(a),len(b))\n",
    "\n",
    "\n",
    "\n",
    "        #count variable to store number of matched words\n",
    "        count=0\n",
    "\n",
    "        #variable for counting the iterations\n",
    "        l=0\n",
    "        #variable to know whether the two products are of same brand or not\n",
    "        sb=0\n",
    "        \n",
    "        #here itertools.zip_longest(a,b) will join the two list in a one list with values as tuple which contains element of a and b in that index     \n",
    "        z=(len(list(itertools.zip_longest(a,b)))-1)\n",
    "        for k in itertools.zip_longest(a,b):\n",
    "            if (k[0] == k[1]):\n",
    "                if any([ l==0, l==1 ]):\n",
    "                    sb+=1\n",
    "\n",
    "                count+=1\n",
    "            l+=1\n",
    "        #if number of words in which both strings differ are >1,we are considering it as different products.\n",
    "        #if number of words in which both strings differ are < 1 and sb<1 then it is a different brand but if sb>1 then they are the same brand with different size or colour. \n",
    "        if (length-count) > 1:################### FOR MORE ACCURACY TUNE THIS PARAMETER.\n",
    "            if i not in marker:\n",
    "                \n",
    "                dedup_prodid.append(data_sorted1[\"productId\"].loc[indices[i]])\n",
    "                marker.append(i)\n",
    "            #if the comaprision is between the last iten and last second item then we append both\n",
    "            if j == num_data-1:\n",
    "                dedup_prodid.append(data_sorted1[\"productId\"].loc[indices[j]])\n",
    "            #since dataset is arranged in alphabetic order so we will change our i when the product changes.\n",
    "            i = j\n",
    "            break\n",
    "        if (length-count) ==1 :################### FOR MORE ACCURACY TUNE THIS PARAMETER.\n",
    "            \n",
    "            if sb <= 1:################### FOR MORE ACCURACY TUNE THIS PARAMETER.\n",
    "                #means different brand names but similar title.means different product\n",
    "                if i not in marker:\n",
    "                    dedup_prodid.append(data_sorted1[\"productId\"].loc[indices[i]])\n",
    "                    marker.append(i)\n",
    "                #since dataset is arranged in alphabetic order so we will change our i when the product changes.\n",
    "                i=j\n",
    "                break\n",
    "                #checking the similarity\n",
    "            if check_similarity(indices[i],indices[j]): ################### FOR MORE ACCURACY TUNE THE VALUE OF SIMILARITY.      \n",
    "                \n",
    "                if j not in marker:\n",
    "                    dup_list.append(data_sorted1[\"productId\"].loc[indices[j]])\n",
    "                    marker.append(j)\n",
    "                dup_dict[data_sorted1[\"productId\"].loc[indices[i]]] = dup_list\n",
    "                j+=1\n",
    "                    \n",
    "             #if it is of same brand but are not similar then we add them to different product list.           \n",
    "            else:\n",
    "                if i not in marker:\n",
    "                    dedup_prodid.append(data_sorted1[\"productId\"].loc[indices[i]])\n",
    "                    marker.append(i)\n",
    "                i=j\n",
    "                break\n",
    "        \n",
    "        if (length-count) == 0 :\n",
    "\n",
    "            if check_similarity(indices[i],indices[j]): ################### FOR MORE ACCURACY TUNE THIS VALUE OF SIMILARITY.      \n",
    "                if j not in marker:\n",
    "                    dup_list.append(data_sorted1[\"productId\"].loc[indices[j]])\n",
    "                    marker.append(j)\n",
    "                    dup_dict[data_sorted1[\"productId\"].loc[indices[i]]] = dup_list\n",
    "                j+=1\n",
    "                    \n",
    "                        \n",
    "            else:\n",
    "                #this is done so that we can move to the next row for comparison and next time i loop runs, it starts with that row which we skipped.\n",
    "                if r_i != i:\n",
    "                    start_i=1\n",
    "                    j_skipped=j\n",
    "                    r_i=i\n",
    "                j+=1\n",
    "     #if somehow i doen't increase we can get out of the loop.                   \n",
    "    if previous_i == i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Finding the similar product from the list of product which don't contain duplicate products( one product with only one size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4946, 9)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dedup_size=data_sorted1[data_sorted1[\"productId\"].isin(dedup_prodid)]\n",
    "data_dedup_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable which holds the index of the data as the indexes are not continuous.\n",
    "indices = []\n",
    "for i,row in data_dedup_size.iterrows():\n",
    "    indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for checking similarity\n",
    "def check_similarity(l,m):\n",
    "    \n",
    "    sim=cosine_similarity(cnn_features[np.where(in_name==l)[0]].reshape(1,-1),cnn_features[np.where(in_name==m)[0]].reshape(1,-1))\n",
    "    if sim > 0.88:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#products without any duplicate titles.\n",
    "dedup_prodid_sim=[]\n",
    "#dictinary store the product as key and their duplictes as values.\n",
    "\n",
    "dup_dict_sim={}\n",
    "\n",
    "r_i=0\n",
    "i=0\n",
    "j=0\n",
    "#list to track the record of the productid processed before.\n",
    "marker=[]\n",
    "start_i=0\n",
    "num_data=data_dedup_size.shape[0]\n",
    "while i < num_data and j<num_data:\n",
    "    if start_i == 1:\n",
    "        i = j_skipped\n",
    "        start_i=0\n",
    "    previous_i=i\n",
    "    #store the words of title as list in a.\n",
    "    a=data_dedup_size['title'].loc[indices[i]].split()\n",
    "\n",
    "    #now we will search for similar product one by one\n",
    "    j=i+1\n",
    "    #for storing the duplicate product ids.\n",
    "    dup_list=[]\n",
    "\n",
    "    while j < num_data:\n",
    "\n",
    "        #store the words of title as list in b.\n",
    "        b=data_dedup_size['title'].loc[indices[j]].split()\n",
    "        #maximum length of the strings.\n",
    "        length=max(len(a),len(b))\n",
    "\n",
    "\n",
    "\n",
    "        #count variable to store number of matched words\n",
    "        count=0\n",
    "\n",
    "        #variable for counting the iterations\n",
    "        l=0\n",
    "        #variable to know whether the two products are of same brand or not\n",
    "        sb=0\n",
    "        \n",
    "        #here itertools.zip_longest(a,b) will join the two list in a one list with values as tuple which contains element of a and b in that index     \n",
    "        z=(len(list(itertools.zip_longest(a,b)))-1)\n",
    "        for k in itertools.zip_longest(a,b):\n",
    "            if (k[0] == k[1]):\n",
    "                if any([ l==0, l==1 ]):\n",
    "                    sb+=1\n",
    "\n",
    "                count+=1\n",
    "            l+=1\n",
    "        #if number of words in which both strings differ are >1,we are considering it as different products.\n",
    "        #if number of words in which both strings differ are < 1 and sb<1 then it is a different brand but if sb>1 then they are the same brand with different size or colour. \n",
    "        if (length-count) > 1:################### FOR MORE ACCURACY TUNE THIS PARAMETER.\n",
    "            if i not in marker:\n",
    "                \n",
    "                dedup_prodid_sim.append(data_dedup_size[\"productId\"].loc[indices[i]])\n",
    "                marker.append(i)\n",
    "            #if the comaprision is between the last iten and last second item then we append both\n",
    "            if j == num_data-1:\n",
    "                dedup_prodid_sim.append(data_dedup_size[\"productId\"].loc[indices[j]])\n",
    "            #since dataset is arranged in alphabetic order so we will change our i when the product changes.\n",
    "            i = j\n",
    "            break\n",
    "            \n",
    "                   \n",
    "        if (length-count) == 0 :\n",
    "\n",
    "            if check_similarity(indices[i],indices[j]):    \n",
    "                if j not in marker:\n",
    "                    dup_list.append(data_dedup_size[\"productId\"].loc[indices[j]])\n",
    "                    marker.append(j)\n",
    "                    dup_dict_sim[data_dedup_size[\"productId\"].loc[indices[i]]] = dup_list\n",
    "                j+=1\n",
    "                    \n",
    "                        \n",
    "            else:\n",
    "\n",
    "                if r_i != i:\n",
    "                    start_i=1\n",
    "                    j_skipped=j\n",
    "                    r_i=i\n",
    "                j+=1\n",
    "        else :\n",
    "            \n",
    "            if sb <= 1:\n",
    "                #means different brand names but similar title.means different product\n",
    "                if i not in marker:\n",
    "                    dedup_prodid_sim.append(data_dedup_size[\"productId\"].loc[indices[i]])\n",
    "                    marker.append(i)\n",
    "                #since dataset is arranged in alphabetic order so we will change our i when the product changes.\n",
    "                i=j\n",
    "                break\n",
    "            if check_similarity(indices[i],indices[j]): ################### FOR MORE ACCURACY TUNE THE VALUE OF SIMILARITY.      \n",
    "                \n",
    "                if j not in marker:\n",
    "                    dup_list.append(data_dedup_size[\"productId\"].loc[indices[j]])\n",
    "                    marker.append(j)\n",
    "                dup_dict_sim[data_dedup_size[\"productId\"].loc[indices[i]]] = dup_list\n",
    "                j+=1\n",
    "            if (length-count)==1:\n",
    "                if r_i != i:\n",
    "                    start_i=1\n",
    "                    j_skipped=j\n",
    "                    r_i=i\n",
    "                j+=1\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                if i not in marker:\n",
    "                    dedup_prodid_sim.append(data_dedup_size[\"productId\"].loc[indices[i]])\n",
    "                    marker.append(i)\n",
    "                i=j\n",
    "                break\n",
    "\n",
    "\n",
    "                        \n",
    "    if previous_i == i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dictionary which contains duplicates(product variants):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dup_dict_size21k.json', 'w') as fp:\n",
    "    json.dump(dup_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dup_dict_size21k.json\") as infile:\n",
    "    data_json_size = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dictionary which contains Similar products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dup_dict_sim21k.json', 'w') as fp:\n",
    "    json.dump(dup_dict_sim, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dup_dict_sim21k.json\") as infile:\n",
    "    data_json_sim = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging both dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dup_dict={}\n",
    "marker=[]\n",
    "for key,value in dup_dict.items():\n",
    "    if key not in marker:\n",
    "        value1=value\n",
    "        marker.append(key)\n",
    "        if key in dup_dict_sim.keys():\n",
    "            value1=value1+dup_dict_sim[key]\n",
    "            for values in dup_dict_sim[key]:\n",
    "                if values in dup_dict.keys():\n",
    "                    value1=value1+dup_dict[values]\n",
    "                    marker.append(values)\n",
    "        \n",
    "        combined_dup_dict[key]=value1\n",
    "not_added=[ele for ele in dup_dict_sim.keys() if ele not in marker]\n",
    "for el in not_added:\n",
    "    if len(dup_dict_sim[el])>0:\n",
    "        combined_dup_dict[el]=dup_dict_sim[el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the whole duplicate dictionary ( different size,colour and Similar Products):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined_dup_dict21k.json', 'w') as fp:\n",
    "    json.dump(combined_dup_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"combined_dup_dict21k.json\") as infile:\n",
    "    combined_json_sim = json.load(infile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
